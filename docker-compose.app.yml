# -----------------------------------------------------------------------------
# App layer: FastAPI inference + Streamlit web UI.
# Uses service-to-service URLs (see .env.docker).
# -----------------------------------------------------------------------------
services:
  api:
    build:
      context: .
      dockerfile: docker/api.Dockerfile
    container_name: dandelion-api
    depends_on:
      minio:
        condition: service_started
    # Load standard in-container environment (S3/MLflow endpoint, etc.)
    env_file:
      - .env.docker
    environment:
      # Explicitly override only what differs from env_file (optional).
      S3_ENDPOINT_URL: http://minio:9000
      S3_ACCESS_KEY: minioadmin
      S3_SECRET_KEY: minioadmin
      S3_MODEL_BUCKET: plant-models
      LOCAL_MODEL_DIR: /models
    ports:
      - "8000:8000"   # API exposed to host
    volumes:
      - models_cache:/models  # cache for downloaded models inside container

  webapp:
    build:
      context: .
      dockerfile: docker/webapp.Dockerfile
    container_name: dandelion-web
    depends_on:
      api:
        condition: service_started
    env_file:
      - .env.docker
    environment:
      # Streamlit calls the API via Docker service name (not localhost).
      API_URL: http://api:8000/predict
    ports:
      - "8501:8501"   # Web UI exposed to host

volumes:
  models_cache: